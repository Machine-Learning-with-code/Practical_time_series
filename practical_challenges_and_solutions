# Advanced Time Series Forecasting for Retail Demand

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from prophet import Prophet
from sklearn.metrics import mean_absolute_error, mean_squared_error
from pmdarima import auto_arima
from scipy.stats import boxcox
from scipy.special import inv_boxcox
from statsmodels.tsa.api import VAR
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import tensorflow as tf

# 9. SARIMA Model
def fit_sarima(data, order=(1,1,1), seasonal_order=(1,1,1,12)):
    """
    Fit a SARIMA model to the time series data.
    
    Args:
    data (pd.Series): Time series data.
    order (tuple): ARIMA model order (p,d,q).
    seasonal_order (tuple): Seasonal order (P,D,Q,s).
    
    Returns:
    SARIMAX: Fitted SARIMA model.
    """
    model = SARIMAX(data, order=order, seasonal_order=seasonal_order)
    return model.fit()

def forecast_sarima(model, steps):
    """
    Generate forecasts using a fitted SARIMA model.
    
    Args:
    model (SARIMAX): Fitted SARIMA model.
    steps (int): Number of steps to forecast.
    
    Returns:
    pd.Series: Forecasted values.
    """
    return model.forecast(steps=steps)

# Example usage:
# sarima_model = fit_sarima(df['y'])
# sarima_forecast = forecast_sarima(sarima_model, steps=30)

# 10. Handling Intermittent Demand (Croston's Method)
def croston(data, alpha=0.4):
    """
    Implement Croston's method for intermittent demand forecasting.
    
    Args:
    data (pd.Series): Time series data.
    alpha (float): Smoothing parameter.
    
    Returns:
    pd.Series: Forecasted values.
    """
    demand = data[data > 0]
    intervals = data.index[data > 0]
    
    if len(demand) == 0:
        return pd.Series(0, index=data.index)
    
    z = demand[0]
    p = (intervals[0] - data.index[0]).days + 1
    
    forecasts = []
    for t, y in data.items():
        if y > 0:
            z = alpha * y + (1 - alpha) * z
            p = alpha * (t - intervals[intervals < t][-1]).days + (1 - alpha) * p
        forecasts.append(z / p)
    
    return pd.Series(forecasts, index=data.index)

# Example usage:
# croston_forecast = croston(df['y'])

# 11. Handling Promotional Effects (RegARIMA)
def fit_regarima(data, exog, order=(1,1,1)):
    """
    Fit a RegARIMA model to account for promotional effects.
    
    Args:
    data (pd.Series): Time series data.
    exog (pd.DataFrame): Exogenous variables (e.g., promotional indicators).
    order (tuple): ARIMA model order (p,d,q).
    
    Returns:
    SARIMAX: Fitted RegARIMA model.
    """
    model = SARIMAX(data, exog=exog, order=order)
    return model.fit()

def forecast_regarima(model, steps, exog_future):
    """
    Generate forecasts using a fitted RegARIMA model.
    
    Args:
    model (SARIMAX): Fitted RegARIMA model.
    steps (int): Number of steps to forecast.
    exog_future (pd.DataFrame): Future values of exogenous variables.
    
    Returns:
    pd.Series: Forecasted values.
    """
    return model.forecast(steps=steps, exog=exog_future)

# Example usage:
# promotional_data = pd.get_dummies(df['promotion_type'])
# regarima_model = fit_regarima(df['y'], exog=promotional_data)
# future_promotions = pd.get_dummies(future_df['promotion_type'])
# regarima_forecast = forecast_regarima(regarima_model, steps=30, exog_future=future_promotions)

# 12. Handling External Factors (Random Forest)
def prepare_data_for_ml(data, external_factors, target_col, lag=7):
    """
    Prepare data for machine learning models, including lagged features.
    
    Args:
    data (pd.DataFrame): Time series data.
    external_factors (list): List of column names for external factors.
    target_col (str): Name of the target column.
    lag (int): Number of lag periods to include.
    
    Returns:
    tuple: X (features) and y (target) for model training.
    """
    df = data.copy()
    for col in [target_col] + external_factors:
        for l in range(1, lag + 1):
            df[f'{col}_lag_{l}'] = df[col].shift(l)
    
    df = df.dropna()
    X = df.drop(columns=[target_col])
    y = df[target_col]
    return X, y

def train_random_forest(X, y):
    """
    Train a Random Forest model for demand forecasting.
    
    Args:
    X (pd.DataFrame): Feature matrix.
    y (pd.Series): Target variable.
    
    Returns:
    RandomForestRegressor: Trained Random Forest model.
    """
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    return model.fit(X, y)

def forecast_random_forest(model, X_future):
    """
    Generate forecasts using a trained Random Forest model.
    
    Args:
    model (RandomForestRegressor): Trained Random Forest model.
    X_future (pd.DataFrame): Future feature values.
    
    Returns:
    np.array: Forecasted values.
    """
    return model.predict(X_future)

# Example usage:
# external_factors = ['temperature', 'is_holiday']
# X, y = prepare_data_for_ml(df, external_factors, 'sales')
# rf_model = train_random_forest(X, y)
# X_future = prepare_future_data(future_df, external_factors)
# rf_forecast = forecast_random_forest(rf_model, X_future)

# 13. Handling Cannibalization Effects (Vector Autoregression)
def fit_var(data, products, lag=1):
    """
    Fit a Vector Autoregression model to capture product interactions.
    
    Args:
    data (pd.DataFrame): Time series data for multiple products.
    products (list): List of product column names.
    lag (int): Number of lag periods.
    
    Returns:
    VAR: Fitted VAR model.
    """
    model = VAR(data[products])
    return model.fit(lag)

def forecast_var(model, steps):
    """
    Generate forecasts using a fitted VAR model.
    
    Args:
    model (VAR): Fitted VAR model.
    steps (int): Number of steps to forecast.
    
    Returns:
    np.array: Forecasted values for all products.
    """
    return model.forecast(model.y, steps=steps)

# Example usage:
# products = ['product_A', 'product_B', 'product_C']
# var_model = fit_var(df, products)
# var_forecast = forecast_var(var_model, steps=30)

# 14. Handling Changing Consumer Behavior (Online Learning)
class OnlineForecaster:
    def __init__(self, input_dim, output_dim):
        self.model = tf.keras.Sequential([
            tf.keras.layers.Dense(64, activation='relu', input_shape=(input_dim,)),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(output_dim)
        ])
        self.model.compile(optimizer='adam', loss='mse')
    
    def update(self, X, y):
        """Update the model with new data."""
        self.model.fit(X, y, epochs=1, verbose=0)
    
    def predict(self, X):
        """Generate predictions."""
        return self.model.predict(X)

# Example usage:
# forecaster = OnlineForecaster(input_dim=10, output_dim=1)
# for t in range(len(df)):
#     X_t = prepare_features(df.iloc[t])
#     y_t = df.iloc[t]['sales']
#     forecaster.update(X_t.reshape(1, -1), np.array([y_t]))
#     forecast_t = forecaster.predict(X_t.reshape(1, -1))

# 15. Handling Stock-outs (Censored Demand Estimation)
def estimate_censored_demand(observed_sales, stock_levels, method='simple'):
    """
    Estimate true demand from censored sales data.
    
    Args:
    observed_sales (pd.Series): Observed sales data.
    stock_levels (pd.Series): Available stock levels.
    method (str): Estimation method ('simple' or 'heckman').
    
    Returns:
    pd.Series: Estimated true demand.
    """
    if method == 'simple':
        return np.maximum(observed_sales, stock_levels)
    elif method == 'heckman':
        # Implement Heckman correction method here
        # This is a placeholder and would require more complex implementation
        pass
    else:
        raise ValueError("Invalid method. Choose 'simple' or 'heckman'.")

# Example usage:
# estimated_demand = estimate_censored_demand(df['observed_sales'], df['stock_levels'])

# 16. Ensemble Forecasting
def ensemble_forecast(models, X, weights=None):
    """
    Generate an ensemble forecast from multiple models.
    
    Args:
    models (list): List of trained models.
    X (pd.DataFrame): Input features.
    weights (list): List of weights for each model (optional).
    
    Returns:
    np.array: Ensemble forecast.
    """
    forecasts = [model.predict(X) for model in models]
    if weights is None:
        weights = [1/len(models)] * len(models)
    return np.average(forecasts, axis=0, weights=weights)

# Example usage:
# models = [arima_model, prophet_model, rf_model]
# ensemble_forecast = ensemble_forecast(models, X_future)

# Utility function for evaluating multiple models
def evaluate_models(actual, forecasts, model_names):
    """
    Evaluate multiple forecasting models.
    
    Args:
    actual (pd.Series): Actual values.
    forecasts (list): List of forecast Series from different models.
    model_names (list): List of model names.
    
    Returns:
    pd.DataFrame: Evaluation metrics for each model.
    """
    results = []
    for forecast, name in zip(forecasts, model_names):
        metrics = calculate_metrics(actual, forecast)
        metrics['Model'] = name
        results.append(metrics)
    return pd.DataFrame(results)

# Example usage:
# actual = df['sales'][-30:]
# forecasts = [arima_forecast, prophet_forecast, rf_forecast]
# model_names = ['ARIMA', 'Prophet', 'Random Forest']
# evaluation = evaluate_models(actual, forecasts, model_names)
# print(evaluation)
